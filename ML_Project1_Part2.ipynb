{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18A4s7SaW9myArqj6TEdcUH9cZINV96ba","timestamp":1719997599532}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split, Subset\n","from torch import optim\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import StratifiedKFold\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# Define the transformation for the CIFAR-10 dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","])\n","\n","# Load the CIFAR-10 dataset\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# Split the training dataset into training (80%) and validation (20%) sets\n","train_size = int(0.8 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","train_data, val_data = random_split(train_dataset, [train_size, val_size])\n","\n","# Create data loaders for training, validation, and testing\n","batch_size = 64\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Define the model\n","class CIFAR10Classifier(nn.Module):\n","    def __init__(self, dropout_rate=0.5):\n","        super(CIFAR10Classifier, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        self.dropout1 = nn.Dropout2d(0.25)\n","        self.dropout2 = nn.Dropout2d(dropout_rate)  # Variable dropout rate for privacy model\n","        self.fc1 = nn.Linear(6272, 64)\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        return x\n","\n","# Training function\n","def train_model(model, train_loader, val_loader, num_epochs=10):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for images, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        # Validate the model\n","        model.eval()\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","                _, predicted = torch.max(outputs, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}%')\n","\n","    return model\n","\n","# Compute losses for a given model and dataset\n","def compute_losses(model, dataset):\n","    model.eval()\n","    losses = []\n","    criterion = nn.CrossEntropyLoss()\n","    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n","    with torch.no_grad():\n","        for images, labels in dataloader:\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            losses.append(loss.item())\n","    return losses\n","\n","# Train an attacker model using losses from train and test datasets\n","def train_attacker_model(losses_train, losses_test):\n","    X = losses_train + losses_test\n","    y = [1] * len(losses_train) + [0] * len(losses_test)\n","    clf = LogisticRegression(random_state=0).fit([[x] for x in X], y)\n","    return clf\n","\n","# Perform cross-validation on the attacker model\n","def cross_val_score(clf, X, y, cv=5):\n","    skf = StratifiedKFold(n_splits=cv)\n","    scores = []\n","    for train_index, test_index in skf.split(X, y):\n","        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n","        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n","        clf.fit([[x] for x in X_train], y_train)\n","        score = clf.score([[x] for x in X_test], y_test)\n","        scores.append(score)\n","    return sum(scores) / len(scores)\n","\n","# Simulation Question 4: Use 80 percent of the CIFAR-10 training data to train your baseline model\n","baseline_model = CIFAR10Classifier()\n","baseline_model = train_model(baseline_model, train_loader, val_loader)\n","\n","# Simulation Question 5: Train your baseline model with privacy enhancements (using higher dropout rate)\n","privacy_model = CIFAR10Classifier(dropout_rate=0.5)  # Modify dropout rate for privacy enhancement\n","privacy_model = train_model(privacy_model, train_loader, val_loader)\n","\n","# Ensure the test accuracy difference between baseline and privacy-enhanced model is less than 15%\n","baseline_model.eval()\n","privacy_model.eval()\n","\n","correct_baseline = 0\n","correct_privacy = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        outputs_baseline = baseline_model(images)\n","        outputs_privacy = privacy_model(images)\n","        _, predicted_baseline = torch.max(outputs_baseline, 1)\n","        _, predicted_privacy = torch.max(outputs_privacy, 1)\n","        total += labels.size(0)\n","        correct_baseline += (predicted_baseline == labels).sum().item()\n","        correct_privacy += (predicted_privacy == labels).sum().item()\n","\n","baseline_accuracy = 100 * correct_baseline / total\n","privacy_accuracy = 100 * correct_privacy / total\n","accuracy_difference = abs(baseline_accuracy - privacy_accuracy)\n","\n","print(f'Baseline Model Test Accuracy: {baseline_accuracy}%')\n","print(f'Privacy Enhanced Model Test Accuracy: {privacy_accuracy}%')\n","print(f'Accuracy Difference: {accuracy_difference}%')\n","\n","assert accuracy_difference < 15, \"The test accuracy difference between the baseline model and the modified model is greater than 15%.\"\n","\n","# Compute losses for baseline and privacy enhanced models\n","baseline_losses_train = compute_losses(baseline_model, train_data)\n","baseline_losses_test = compute_losses(baseline_model, test_dataset)\n","privacy_losses_train = compute_losses(privacy_model, train_data)\n","privacy_losses_test = compute_losses(privacy_model, test_dataset)\n","\n","# Simulation Question 6: Train two Attacker Models based on MIA techniques learned in Phase 0\n","# Using 80 percent of the training data as your seen data, and the remaining training data along with the test data as your unseen data\n","\n","# Split the training data into seen and unseen parts\n","seen_data_size = int(0.8 * len(train_data))\n","unseen_data_size = len(train_data) - seen_data_size\n","seen_data, unseen_data_train = random_split(train_data, [seen_data_size, unseen_data_size])\n","\n","# Combine unseen training data with test data for unseen dataset\n","unseen_data = Subset(train_dataset, unseen_data_train.indices) + Subset(test_dataset, range(len(test_dataset)))\n","\n","# Compute losses for seen and unseen datasets for baseline and privacy enhanced models\n","baseline_losses_seen = compute_losses(baseline_model, seen_data)\n","baseline_losses_unseen = compute_losses(baseline_model, unseen_data)\n","privacy_losses_seen = compute_losses(privacy_model, seen_data)\n","privacy_losses_unseen = compute_losses(privacy_model, unseen_data)\n","\n","# Train attacker models\n","baseline_attacker = train_attacker_model(baseline_losses_seen, baseline_losses_unseen)\n","privacy_attacker = train_attacker_model(privacy_losses_seen, privacy_losses_unseen)\n","\n","# Evaluate attacker models\n","baseline_attack_score = cross_val_score(baseline_attacker, baseline_losses_seen + baseline_losses_unseen, [1]*len(baseline_losses_seen) + [0]*len(baseline_losses_unseen), cv=5)\n","privacy_attack_score = cross_val_score(privacy_attacker, privacy_losses_seen + privacy_losses_unseen, [1]*len(privacy_losses_seen) + [0]*len(privacy_losses_unseen), cv=5)\n","\n","print(f'Baseline Model MIA Accuracy: {baseline_attack_score}')\n","print(f'Privacy Enhanced Model MIA Accuracy: {privacy_attack_score}')\n","\n","# Simulation Question 7: Improve your attacker models to achieve better MIA accuracy for both the baseline and modified models\n","# (e.g., by increasing the number of shadow models)\n","\n","def train_shadow_models(model, num_shadow_models, train_data):\n","    shadow_models = []\n","    for _ in range(num_shadow_models):\n","        shadow_data_size = int(0.5 * len(train_data))\n","        shadow_data, _ = random_split(train_data, [shadow_data_size, len(train_data) - shadow_data_size])\n","        shadow_model = CIFAR10Classifier()\n","        shadow_model = train_model(shadow_model, DataLoader(shadow_data, batch_size=batch_size, shuffle=True), val_loader)\n","        shadow_models.append(shadow_model)\n","    return shadow_models\n","\n","def compute_shadow_losses(shadow_models, dataset):\n","    all_losses = []\n","    for model in shadow_models:\n","        losses = compute_losses(model, dataset)\n","        all_losses.extend(losses)\n","    return all_losses\n","\n","# Train more shadow models to improve MIA accuracy\n","num_shadow_models = 5\n","baseline_shadow_models = train_shadow_models(baseline_model, num_shadow_models, train_data)\n","privacy_shadow_models = train_shadow_models(privacy_model, num_shadow_models, train_data)\n","\n","baseline_shadow_losses_seen = compute_shadow_losses(baseline_shadow_models, seen_data)\n","baseline_shadow_losses_unseen = compute_shadow_losses(baseline_shadow_models, unseen_data)\n","privacy_shadow_losses_seen = compute_shadow_losses(privacy_shadow_models, seen_data)\n","privacy_shadow_losses_unseen = compute_shadow_losses(privacy_shadow_models, unseen_data)\n","\n","# Train improved attacker models\n","baseline_improved_attacker = train_attacker_model(baseline_shadow_losses_seen, baseline_shadow_losses_unseen)\n","privacy_improved_attacker = train_attacker_model(privacy_shadow_losses_seen, privacy_shadow_losses_unseen)\n","\n","# Evaluate improved attacker models\n","baseline_improved_attack_score = cross_val_score(baseline_improved_attacker, baseline_shadow_losses_seen + baseline_shadow_losses_unseen, [1]*len(baseline_shadow_losses_seen) + [0]*len(baseline_shadow_losses_unseen), cv=5)\n","privacy_improved_attack_score = cross_val_score(privacy_improved_attacker, privacy_shadow_losses_seen + privacy_shadow_losses_unseen, [1]*len(privacy_shadow_losses_seen) + [0]*len(privacy_shadow_losses_unseen), cv=5)\n","\n","print(f'Improved Baseline Model MIA Accuracy: {baseline_improved_attack_score}')\n","print(f'Improved Privacy Enhanced Model MIA Accuracy: {privacy_improved_attack_score}')"],"metadata":{"id":"xaxmNi1A61hi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719856570914,"user_tz":-210,"elapsed":868,"user":{"displayName":"Pooria Rad","userId":"18089175725627319477"}},"outputId":"924d2dba-4d6c-4d9c-c7a2-ca0ce2a46978","collapsed":true},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:10<00:00, 15876890.84it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch [1/10], Loss: 1.7254384632110595, Validation Loss: 1.3675755239596032, Accuracy: 51.02%\n","Epoch [2/10], Loss: 1.457023900604248, Validation Loss: 1.251373583723785, Accuracy: 56.54%\n","Epoch [3/10], Loss: 1.342502292060852, Validation Loss: 1.11584126114086, Accuracy: 60.16%\n","Epoch [4/10], Loss: 1.2699505160331725, Validation Loss: 1.0908929925815316, Accuracy: 62.47%\n","Epoch [5/10], Loss: 1.2230305458068849, Validation Loss: 1.0559498261494242, Accuracy: 63.26%\n","Epoch [6/10], Loss: 1.1730464163780212, Validation Loss: 1.02546154465645, Accuracy: 64.23%\n","Epoch [7/10], Loss: 1.1430781538009644, Validation Loss: 1.0202108572243125, Accuracy: 64.41%\n","Epoch [8/10], Loss: 1.117153731918335, Validation Loss: 0.9985991332940994, Accuracy: 65.34%\n","Epoch [9/10], Loss: 1.0851118191719056, Validation Loss: 0.9915223831583739, Accuracy: 64.92%\n","Epoch [10/10], Loss: 1.0668078775405885, Validation Loss: 0.9968324094820934, Accuracy: 65.03%\n","Epoch [1/10], Loss: 1.7464744194030761, Validation Loss: 1.3591258419547112, Accuracy: 52.55%\n","Epoch [2/10], Loss: 1.4590797147750854, Validation Loss: 1.1853015468378736, Accuracy: 58.34%\n","Epoch [3/10], Loss: 1.3485068564414977, Validation Loss: 1.121040020399033, Accuracy: 61.38%\n","Epoch [4/10], Loss: 1.2785508786201476, Validation Loss: 1.0986328003512826, Accuracy: 62.36%\n","Epoch [5/10], Loss: 1.2442805852890015, Validation Loss: 1.0581243296337735, Accuracy: 63.24%\n","Epoch [6/10], Loss: 1.2012303826332091, Validation Loss: 1.049252174082835, Accuracy: 63.65%\n","Epoch [7/10], Loss: 1.1690854732513427, Validation Loss: 1.0243082335040827, Accuracy: 64.07%\n","Epoch [8/10], Loss: 1.1389644931793212, Validation Loss: 1.0164751919211856, Accuracy: 64.68%\n","Epoch [9/10], Loss: 1.1167678135871888, Validation Loss: 1.0318808551806553, Accuracy: 63.67%\n","Epoch [10/10], Loss: 1.0937654722213745, Validation Loss: 1.0125363507088583, Accuracy: 64.99%\n","Baseline Model Test Accuracy: 64.97%\n","Privacy Enhanced Model Test Accuracy: 64.81%\n","Accuracy Difference: 0.1599999999999966%\n","Baseline Model MIA Accuracy: 0.7544421233718358\n","Privacy Enhanced Model MIA Accuracy: 0.7397149176701893\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch [1/10], Loss: 1.8475659647688698, Validation Loss: 1.5653636197375644, Accuracy: 45.07%\n","Epoch [2/10], Loss: 1.5763182274449747, Validation Loss: 1.383731957453831, Accuracy: 52.35%\n","Epoch [3/10], Loss: 1.4675977051067657, Validation Loss: 1.2830926840472374, Accuracy: 53.72%\n","Epoch [4/10], Loss: 1.3893273714632273, Validation Loss: 1.22070997497838, Accuracy: 56.31%\n","Epoch [5/10], Loss: 1.3168415979455455, Validation Loss: 1.176879437865725, Accuracy: 58.32%\n","Epoch [6/10], Loss: 1.2713214124734409, Validation Loss: 1.158451150557038, Accuracy: 58.89%\n","Epoch [7/10], Loss: 1.2320322807604513, Validation Loss: 1.139693812959513, Accuracy: 59.21%\n","Epoch [8/10], Loss: 1.1862862033965869, Validation Loss: 1.1150618514437585, Accuracy: 60.71%\n","Epoch [9/10], Loss: 1.1512825953693817, Validation Loss: 1.1138472963290609, Accuracy: 60.19%\n","Epoch [10/10], Loss: 1.1147949651788218, Validation Loss: 1.087233344081101, Accuracy: 61.77%\n","Epoch [1/10], Loss: 1.8583315389986617, Validation Loss: 1.4939233307625837, Accuracy: 48.59%\n","Epoch [2/10], Loss: 1.5792182352596198, Validation Loss: 1.3474811186456377, Accuracy: 53.19%\n","Epoch [3/10], Loss: 1.4698944251758221, Validation Loss: 1.2837761124228215, Accuracy: 54.92%\n","Epoch [4/10], Loss: 1.3991844240849771, Validation Loss: 1.218868608687334, Accuracy: 57.33%\n","Epoch [5/10], Loss: 1.3334645150949398, Validation Loss: 1.1819473706233274, Accuracy: 59.52%\n","Epoch [6/10], Loss: 1.2859528712190378, Validation Loss: 1.1708488172026956, Accuracy: 60.46%\n","Epoch [7/10], Loss: 1.232549580903099, Validation Loss: 1.1171301652671426, Accuracy: 60.83%\n","Epoch [8/10], Loss: 1.1779526658713246, Validation Loss: 1.1217644730950618, Accuracy: 60.53%\n","Epoch [9/10], Loss: 1.1602681581966412, Validation Loss: 1.1039408589624295, Accuracy: 61.07%\n","Epoch [10/10], Loss: 1.122991169603488, Validation Loss: 1.0854530288914965, Accuracy: 62.17%\n","Epoch [1/10], Loss: 1.8692122332204264, Validation Loss: 1.4998840587154316, Accuracy: 48.09%\n","Epoch [2/10], Loss: 1.5882652548555367, Validation Loss: 1.3872238169809816, Accuracy: 53.39%\n","Epoch [3/10], Loss: 1.4776259999686536, Validation Loss: 1.2643218055652206, Accuracy: 55.77%\n","Epoch [4/10], Loss: 1.3983571338958252, Validation Loss: 1.2326198394890804, Accuracy: 57.68%\n","Epoch [5/10], Loss: 1.33408482348957, Validation Loss: 1.1856897317679824, Accuracy: 58.74%\n","Epoch [6/10], Loss: 1.2903163713007308, Validation Loss: 1.1692158621587572, Accuracy: 59.13%\n","Epoch [7/10], Loss: 1.236924507747443, Validation Loss: 1.1411406302907665, Accuracy: 61.3%\n","Epoch [8/10], Loss: 1.1901982540901477, Validation Loss: 1.123837005560565, Accuracy: 60.3%\n","Epoch [9/10], Loss: 1.1545771990721219, Validation Loss: 1.1043246263151716, Accuracy: 61.44%\n","Epoch [10/10], Loss: 1.1234954218514048, Validation Loss: 1.0954648757436474, Accuracy: 61.51%\n","Epoch [1/10], Loss: 1.8758135592213834, Validation Loss: 1.517022709178317, Accuracy: 47.67%\n","Epoch [2/10], Loss: 1.593459777938672, Validation Loss: 1.368313015646236, Accuracy: 51.33%\n","Epoch [3/10], Loss: 1.4804772504221517, Validation Loss: 1.2800492640513523, Accuracy: 55.21%\n","Epoch [4/10], Loss: 1.3941043264949664, Validation Loss: 1.2282676355094666, Accuracy: 57.74%\n","Epoch [5/10], Loss: 1.324697965821519, Validation Loss: 1.158181938396138, Accuracy: 59.13%\n","Epoch [6/10], Loss: 1.2699894051963148, Validation Loss: 1.1311440069204683, Accuracy: 60.71%\n","Epoch [7/10], Loss: 1.2140907828038492, Validation Loss: 1.1102907262789976, Accuracy: 61.7%\n","Epoch [8/10], Loss: 1.1903289263240826, Validation Loss: 1.1066814118130193, Accuracy: 61.28%\n","Epoch [9/10], Loss: 1.171200474991966, Validation Loss: 1.1089399673376874, Accuracy: 61.37%\n","Epoch [10/10], Loss: 1.1070072262431867, Validation Loss: 1.0917230643284548, Accuracy: 61.93%\n","Epoch [1/10], Loss: 1.89553899924976, Validation Loss: 1.5210140457578525, Accuracy: 46.62%\n","Epoch [2/10], Loss: 1.627959732811291, Validation Loss: 1.3933211170184385, Accuracy: 51.19%\n","Epoch [3/10], Loss: 1.5054725332382006, Validation Loss: 1.2827089174537902, Accuracy: 54.3%\n","Epoch [4/10], Loss: 1.4154656984554692, Validation Loss: 1.2392406137126266, Accuracy: 57.03%\n","Epoch [5/10], Loss: 1.3548637169618576, Validation Loss: 1.187884460588929, Accuracy: 58.29%\n","Epoch [6/10], Loss: 1.2971269695903547, Validation Loss: 1.1507984843983012, Accuracy: 59.65%\n","Epoch [7/10], Loss: 1.2471539195353232, Validation Loss: 1.126280684380015, Accuracy: 60.21%\n","Epoch [8/10], Loss: 1.2116376641459359, Validation Loss: 1.1215286402945306, Accuracy: 60.32%\n","Epoch [9/10], Loss: 1.1752044920342417, Validation Loss: 1.1104256715744165, Accuracy: 61.27%\n","Epoch [10/10], Loss: 1.1316242996876993, Validation Loss: 1.0987240379782999, Accuracy: 61.9%\n","Epoch [1/10], Loss: 1.8824193690912412, Validation Loss: 1.5231737308441453, Accuracy: 46.3%\n","Epoch [2/10], Loss: 1.6052154965294054, Validation Loss: 1.3778304932223764, Accuracy: 52.67%\n","Epoch [3/10], Loss: 1.4825598203336088, Validation Loss: 1.2975565817705386, Accuracy: 54.65%\n","Epoch [4/10], Loss: 1.4122054344548967, Validation Loss: 1.2750781258200383, Accuracy: 55.8%\n","Epoch [5/10], Loss: 1.3416315100063532, Validation Loss: 1.2219671067918183, Accuracy: 56.76%\n","Epoch [6/10], Loss: 1.299077987290038, Validation Loss: 1.1735958251983496, Accuracy: 58.3%\n","Epoch [7/10], Loss: 1.2434472717797032, Validation Loss: 1.1455553705525245, Accuracy: 59.27%\n","Epoch [8/10], Loss: 1.1947664570884582, Validation Loss: 1.1403022917212955, Accuracy: 59.64%\n","Epoch [9/10], Loss: 1.1644188569376643, Validation Loss: 1.106145282839514, Accuracy: 61.08%\n","Epoch [10/10], Loss: 1.1265347563801482, Validation Loss: 1.0900764389402549, Accuracy: 61.36%\n","Epoch [1/10], Loss: 1.81761156636686, Validation Loss: 1.467599255264185, Accuracy: 47.36%\n","Epoch [2/10], Loss: 1.5463146664464056, Validation Loss: 1.336290234213422, Accuracy: 52.99%\n","Epoch [3/10], Loss: 1.428613756792233, Validation Loss: 1.2688882927985707, Accuracy: 55.66%\n","Epoch [4/10], Loss: 1.3445369881182052, Validation Loss: 1.1966542104247269, Accuracy: 58.44%\n","Epoch [5/10], Loss: 1.2821951546608068, Validation Loss: 1.1781622471323439, Accuracy: 59.43%\n","Epoch [6/10], Loss: 1.2303242742443998, Validation Loss: 1.1304867127139098, Accuracy: 60.29%\n","Epoch [7/10], Loss: 1.1908715283527922, Validation Loss: 1.1287240124052498, Accuracy: 60.5%\n","Epoch [8/10], Loss: 1.138248115492324, Validation Loss: 1.099823501839, Accuracy: 61.58%\n","Epoch [9/10], Loss: 1.0950586395903517, Validation Loss: 1.0953315952021605, Accuracy: 61.71%\n","Epoch [10/10], Loss: 1.0718460507667102, Validation Loss: 1.0843184279028777, Accuracy: 62.12%\n","Epoch [1/10], Loss: 1.868562333119182, Validation Loss: 1.505193257787425, Accuracy: 47.61%\n","Epoch [2/10], Loss: 1.5860091729666859, Validation Loss: 1.3374569841251251, Accuracy: 52.38%\n","Epoch [3/10], Loss: 1.478620355502485, Validation Loss: 1.2879949269021393, Accuracy: 54.31%\n","Epoch [4/10], Loss: 1.3891436969891142, Validation Loss: 1.2089032899042604, Accuracy: 58.28%\n","Epoch [5/10], Loss: 1.3339223610326505, Validation Loss: 1.1897975183596277, Accuracy: 59.05%\n","Epoch [6/10], Loss: 1.2716370164015043, Validation Loss: 1.1626562700150118, Accuracy: 59.33%\n","Epoch [7/10], Loss: 1.2285030215692978, Validation Loss: 1.1209218073043095, Accuracy: 60.62%\n","Epoch [8/10], Loss: 1.1898600043961034, Validation Loss: 1.1285483294231877, Accuracy: 60.36%\n","Epoch [9/10], Loss: 1.1584483103249401, Validation Loss: 1.118167161561881, Accuracy: 60.41%\n","Epoch [10/10], Loss: 1.1123544143411679, Validation Loss: 1.0903628130627285, Accuracy: 61.14%\n","Epoch [1/10], Loss: 1.8663772832090482, Validation Loss: 1.482169180918651, Accuracy: 48.32%\n","Epoch [2/10], Loss: 1.5939756388100572, Validation Loss: 1.3811448356907838, Accuracy: 51.14%\n","Epoch [3/10], Loss: 1.4938033781112574, Validation Loss: 1.2621633755932948, Accuracy: 55.53%\n","Epoch [4/10], Loss: 1.4191486949737842, Validation Loss: 1.2362588928763274, Accuracy: 55.23%\n","Epoch [5/10], Loss: 1.3517681135537145, Validation Loss: 1.2050861887111786, Accuracy: 58.09%\n","Epoch [6/10], Loss: 1.2911224161474089, Validation Loss: 1.1530408255613533, Accuracy: 60.12%\n","Epoch [7/10], Loss: 1.2445789417519737, Validation Loss: 1.141705705861377, Accuracy: 59.44%\n","Epoch [8/10], Loss: 1.2032256259704932, Validation Loss: 1.1219881427515843, Accuracy: 60.43%\n","Epoch [9/10], Loss: 1.1695382939740873, Validation Loss: 1.1122908394807463, Accuracy: 60.75%\n","Epoch [10/10], Loss: 1.1411810193579799, Validation Loss: 1.1043827636226726, Accuracy: 60.71%\n","Epoch [1/10], Loss: 1.8676499695823596, Validation Loss: 1.4774196983143022, Accuracy: 46.89%\n","Epoch [2/10], Loss: 1.5627992259808623, Validation Loss: 1.3475162975347725, Accuracy: 53.41%\n","Epoch [3/10], Loss: 1.434629847066471, Validation Loss: 1.2306946762807809, Accuracy: 56.4%\n","Epoch [4/10], Loss: 1.3597590237760697, Validation Loss: 1.1928280117405448, Accuracy: 57.89%\n","Epoch [5/10], Loss: 1.28622133453814, Validation Loss: 1.1930106794758208, Accuracy: 57.97%\n","Epoch [6/10], Loss: 1.2467835939730318, Validation Loss: 1.1275839889125459, Accuracy: 60.43%\n","Epoch [7/10], Loss: 1.204535826326559, Validation Loss: 1.1182906547929072, Accuracy: 60.38%\n","Epoch [8/10], Loss: 1.171162706975358, Validation Loss: 1.099620364274189, Accuracy: 61.38%\n","Epoch [9/10], Loss: 1.1303852488057682, Validation Loss: 1.103751408826014, Accuracy: 61.16%\n","Epoch [10/10], Loss: 1.1079068461926982, Validation Loss: 1.0964357564403753, Accuracy: 61.42%\n","Improved Baseline Model MIA Accuracy: 0.6685860524632117\n","Improved Privacy Enhanced Model MIA Accuracy: 0.6744721689059501\n"]}]},{"cell_type":"markdown","source":["تنها سل ۲ و ۳ مد نظر هستند."],"metadata":{"id":"zdjyisjP11Wu"}},{"cell_type":"code","source":["# With dp sgd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split, Subset, ConcatDataset\n","from torch import optim\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import StratifiedKFold\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# Define the transformation for the CIFAR-10 dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","])\n","\n","# Load the CIFAR-10 dataset\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# Split the training dataset into training (80%) and validation (20%) sets\n","train_size = int(0.8 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","train_data, val_data = random_split(train_dataset, [train_size, val_size])\n","\n","# Create data loaders for training, validation, and testing\n","batch_size = 64\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Define the model\n","class CIFAR10Classifier(nn.Module):\n","    def __init__(self, dropout_rate=0.5):\n","        super(CIFAR10Classifier, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        self.dropout1 = nn.Dropout2d(0.25)\n","        self.dropout2 = nn.Dropout2d(dropout_rate)\n","        self.fc1 = nn.Linear(6272, 64)\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        return x\n","\n","# Training function\n","def train_model(model, train_loader, val_loader, num_epochs=10):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for images, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        # Validate the model\n","        model.eval()\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","                _, predicted = torch.max(outputs, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}%')\n","    return model\n","\n","# Compute losses for a given model and dataset\n","def compute_losses(model, dataset):\n","    model.eval()\n","    losses = []\n","    criterion = nn.CrossEntropyLoss()\n","    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n","    with torch.no_grad():\n","        for images, labels in dataloader:\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            losses.append(loss.item())\n","    return losses\n","\n","# Train an attacker model using losses from train and test datasets\n","# در واقعیت برای اینکه بتواند به مدل حمله کند، از میانگین یادگیری بر دو گروه\n","# مختلف دیتاست که از دیتاست منبع ساخته‌ایم استفاده می‌کنیم.\n","def train_attacker_model(losses_train, losses_test):\n","    X = losses_train + losses_test\n","    y = [1] * len(losses_train) + [0] * len(losses_test)\n","    clf = LogisticRegression(random_state=0).fit([[x] for x in X], y)\n","    return clf\n","\n","# Perform cross-validation on the attacker model\n","def cross_val_score(clf, X, y, cv=5):\n","    skf = StratifiedKFold(n_splits=cv)\n","    scores = []\n","    for train_index, test_index in skf.split(X, y):\n","        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n","        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n","        clf.fit([[x] for x in X_train], y_train)\n","        score = clf.score([[x] for x in X_test], y_test)\n","        scores.append(score)\n","    return sum(scores) / len(scores)\n","\n","# Simulation Question 4: Use 80 percent of the CIFAR-10 training data to train your baseline model\n","baseline_model = CIFAR10Classifier()\n","baseline_model = train_model(baseline_model, train_loader, val_loader)\n","\n","# Simulation Question 5: Train your baseline model with privacy enhancements (using higher dropout rate)\n","privacy_model = CIFAR10Classifier(dropout_rate=0.5)  # Modify dropout rate for privacy enhancement\n","privacy_model = train_model(privacy_model, train_loader, val_loader)\n","\n","# Ensure the test accuracy difference between baseline and privacy-enhanced model is less than 15%\n","baseline_model.eval()\n","privacy_model.eval()\n","\n","correct_baseline = 0\n","correct_privacy = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        outputs_baseline = baseline_model(images)\n","        outputs_privacy = privacy_model(images)\n","        _, predicted_baseline = torch.max(outputs_baseline, 1)\n","        _, predicted_privacy = torch.max(outputs_privacy, 1)\n","        total += labels.size(0)\n","        correct_baseline += (predicted_baseline == labels).sum().item()\n","        correct_privacy += (predicted_privacy == labels).sum().item()\n","\n","baseline_accuracy = 100 * correct_baseline / total\n","privacy_accuracy = 100 * correct_privacy / total\n","accuracy_difference = abs(baseline_accuracy - privacy_accuracy)\n","\n","print(f'Baseline Model Test Accuracy: {baseline_accuracy}%')\n","print(f'Privacy Enhanced Model Test Accuracy: {privacy_accuracy}%')\n","print(f'Accuracy Difference: {accuracy_difference}%')\n","\n","assert accuracy_difference < 15, \"The test accuracy difference between the baseline model and the modified model is greater than 15%.\"\n","\n","# Compute losses for baseline and privacy enhanced models\n","baseline_losses_train = compute_losses(baseline_model, train_data)\n","baseline_losses_test = compute_losses(baseline_model, test_dataset)\n","privacy_losses_train = compute_losses(privacy_model, train_data)\n","privacy_losses_test = compute_losses(privacy_model, test_dataset)\n","\n","# Simulation Question 6: Train two Attacker Models based on MIA techniques learned in Phase 0\n","# Using 80 percent of the training data as your seen data, and the remaining training data along with the test data as your unseen data\n","\n","# Split the training data into seen and unseen parts\n","seen_data_size = int(0.8 * len(train_data))\n","unseen_data_size = len(train_data) - seen_data_size\n","seen_data, unseen_data_train = random_split(train_data, [seen_data_size, unseen_data_size])\n","\n","# Combine unseen training data with test data for unseen dataset\n","unseen_data = ConcatDataset([Subset(train_dataset, unseen_data_train.indices), test_dataset])\n","\n","# Compute losses for seen and unseen datasets for baseline and privacy enhanced models\n","baseline_losses_seen = compute_losses(baseline_model, seen_data)\n","baseline_losses_unseen = compute_losses(baseline_model, unseen_data)\n","privacy_losses_seen = compute_losses(privacy_model, seen_data)\n","privacy_losses_unseen = compute_losses(privacy_model, unseen_data)\n","\n","# Train attacker models for both baseline and privacy enhanced models\n","baseline_attacker = train_attacker_model(baseline_losses_seen, baseline_losses_unseen)\n","privacy_attacker = train_attacker_model(privacy_losses_seen, privacy_losses_unseen)\n","\n","# Evaluate attacker models\n","baseline_attack_score = cross_val_score(baseline_attacker, baseline_losses_seen + baseline_losses_unseen, [1]*len(baseline_losses_seen) + [0]*len(baseline_losses_unseen), cv=5)\n","privacy_attack_score = cross_val_score(privacy_attacker, privacy_losses_seen + privacy_losses_unseen, [1]*len(privacy_losses_seen) + [0]*len(privacy_losses_unseen), cv=5)\n","\n","print(f'Baseline Model MIA Accuracy: {baseline_attack_score}')\n","print(f'Privacy Enhanced Model MIA Accuracy: {privacy_attack_score}')\n","\n","# Simulation Question 7: Improve your attacker models to achieve better MIA accuracy for both the baseline and modified models\n","# (e.g., by increasing the number of shadow models)\n","\n","def train_shadow_models(model, num_shadow_models, train_data):\n","    shadow_models = []\n","    for _ in range(num_shadow_models):\n","        shadow_train_data, shadow_val_data = random_split(train_data, [int(0.8*len(train_data)), int(0.2*len(train_data))])\n","        shadow_model = model.__class__()  # Create a new instance of the model\n","        shadow_model = train_model(shadow_model, DataLoader(shadow_train_data, batch_size=batch_size, shuffle=True), DataLoader(shadow_val_data, batch_size=batch_size, shuffle=False))\n","        shadow_models.append(shadow_model)\n","    return shadow_models\n","\n","num_shadow_models = 5\n","baseline_shadow_models = train_shadow_models(baseline_model, num_shadow_models, train_data)\n","privacy_shadow_models = train_shadow_models(privacy_model, num_shadow_models, train_data)\n","\n","# Compute losses for shadow models\n","baseline_shadow_losses_train = []\n","baseline_shadow_losses_test = []\n","privacy_shadow_losses_train = []\n","privacy_shadow_losses_test = []\n","\n","for shadow_model in baseline_shadow_models:\n","    baseline_shadow_losses_train.extend(compute_losses(shadow_model, train_data))\n","    baseline_shadow_losses_test.extend(compute_losses(shadow_model, test_dataset))\n","\n","for shadow_model in privacy_shadow_models:\n","    privacy_shadow_losses_train.extend(compute_losses(shadow_model, train_data))\n","    privacy_shadow_losses_test.extend(compute_losses(shadow_model, test_dataset))\n","\n","# Train improved attacker models using shadow models\n","improved_baseline_attacker = train_attacker_model(baseline_shadow_losses_train, baseline_shadow_losses_test)\n","improved_privacy_attacker = train_attacker_model(privacy_shadow_losses_train, privacy_shadow_losses_test)\n","\n","# Evaluate improved attacker models\n","improved_baseline_attack_score = cross_val_score(improved_baseline_attacker, baseline_shadow_losses_train + baseline_shadow_losses_test, [1]*len(baseline_shadow_losses_train) + [0]*len(baseline_shadow_losses_test), cv=5)\n","improved_privacy_attack_score = cross_val_score(improved_privacy_attacker, privacy_shadow_losses_train + privacy_shadow_losses_test, [1]*len(privacy_shadow_losses_train) + [0]*len(privacy_shadow_losses_test), cv=5)\n","\n","print(f'Improved Baseline Model MIA Accuracy: {improved_baseline_attack_score}')\n","print(f'Improved Privacy Enhanced Model MIA Accuracy: {improved_privacy_attack_score}')"],"metadata":{"id":"-TK1tWz0IGpc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4283a82c-27af-4ef6-b236-c047bd56ea3a","collapsed":true},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 49671293.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 1.735023225402832, Validation Loss: 1.369295563667443, Accuracy: 51.32%\n","Epoch [2/10], Loss: 1.4670258842468262, Validation Loss: 1.2091545523351925, Accuracy: 57.6%\n","Epoch [3/10], Loss: 1.346752587032318, Validation Loss: 1.1065926965634534, Accuracy: 61.62%\n","Epoch [4/10], Loss: 1.2856727949142457, Validation Loss: 1.0934479593471358, Accuracy: 62.44%\n","Epoch [5/10], Loss: 1.2272003404617309, Validation Loss: 1.0420442618382204, Accuracy: 63.7%\n","Epoch [6/10], Loss: 1.1788294010162355, Validation Loss: 1.0238931156267785, Accuracy: 64.54%\n","Epoch [7/10], Loss: 1.1528226181983947, Validation Loss: 1.0019858984430885, Accuracy: 64.89%\n","Epoch [8/10], Loss: 1.1196374527931214, Validation Loss: 1.0026190155630659, Accuracy: 64.71%\n","Epoch [9/10], Loss: 1.093772953414917, Validation Loss: 0.9944881075506757, Accuracy: 65.48%\n"]}]},{"cell_type":"code","source":["pip install gdown"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzP0OmW3yOs7","executionInfo":{"status":"ok","timestamp":1719963029836,"user_tz":-210,"elapsed":6966,"user":{"displayName":"Pooria Rad","userId":"18089175725627319477"}},"outputId":"da602ae5-bef9-4dc1-8896-a897c9ab8d6d","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.6.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}]},{"cell_type":"code","source":["import gdown\n","from torchvision import models\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torchvision.datasets import CIFAR10\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score ,f1_score\n","from torch.utils.data import Subset, TensorDataset\n","\n","# Define the CIFAR10Classifier model\n","class CIFAR10Classifier(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10Classifier, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        self.dropout1 = nn.Dropout2d(0.25)\n","        self.dropout2 = nn.Dropout2d(0.5)\n","        self.fc1 = nn.Linear(6272, 64)\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        return x\n","\n","# Download the files from Google Drive\n","gdown.download('https://drive.google.com/uc?id=1u8TtbKu-IYn4BM2fMxlKuSxebGm8t0a8', 'list.txt', quiet=False)\n","gdown.download('https://drive.google.com/uc?id=13JqLGTHtspZes2xc3JHPgszM2RkvJtsR', 'model_state_dict.pth', quiet=False)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Load the pre-trained model\n","model = CIFAR10Classifier()\n","state_dict = torch.load(\"model_state_dict.pth\", map_location=device)\n","new_state_dict = {key.replace('_module.', ''): value for key, value in state_dict.items()}\n","model.load_state_dict(new_state_dict)\n","model.to(device)\n","model.eval()\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","DATA_ROOT = '../cifar10'\n","BATCH_SIZE = 64\n","\n","# Load the indices from list.txt\n","indices_file = 'list.txt'\n","with open(indices_file, 'r') as f:\n","    indices = [int(line.strip()) for line in f]\n","\n","full_train_dataset = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform)\n","test_dataset = CIFAR10(root=DATA_ROOT, train=False, download=True, transform=transform)\n","\n","train_indices_set = set(indices)\n","all_indices = set(range(len(full_train_dataset)))\n","other_indices = list(all_indices - train_indices_set)\n","\n","train_dataset = Subset(full_train_dataset, indices[:len(indices)//2])\n","other_dataset = Subset(full_train_dataset, other_indices)\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","other_loader = DataLoader(other_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# Create labels\n","train_labels = torch.ones(len(train_dataset)).to(device)\n","other_labels = torch.zeros(len(other_dataset)).to(device)\n","test_labels = torch.zeros(len(test_dataset)).to(device)\n","\n","def extract_features(model, dataloader):\n","    model.eval()\n","    features = []\n","    with torch.no_grad():\n","        for data in dataloader:\n","            inputs, _ = data\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            features.append(outputs)\n","    return torch.cat(features).to(device)\n","\n","train_features = extract_features(model, train_loader)\n","other_features = extract_features(model, other_loader)\n","test_features = extract_features(model, test_loader)\n","\n","combined_features = torch.cat((train_features, other_features, test_features))\n","combined_labels = torch.cat((train_labels, other_labels, test_labels))\n","\n","new_dataset = TensorDataset(combined_features, combined_labels)\n","new_loader = DataLoader(new_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Define and train the attacker model\n","class AttackerModel(nn.Module):\n","    def __init__(self):\n","        super(AttackerModel, self).__init__()\n","        self.fc1 = nn.Linear(10, 64)\n","        self.fc2 = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = torch.sigmoid(self.fc2(x))\n","        return x\n","\n","attacker = AttackerModel().to(device)\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(attacker.parameters(), lr=0.001)\n","\n","EPOCHS = 10\n","\n","for epoch in range(EPOCHS):\n","    attacker.train()\n","    running_loss = 0.0\n","    for features, labels in new_loader:\n","        features, labels = features.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = attacker(features).squeeze()\n","        loss = criterion(outputs, labels.float())\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(new_loader):.4f}')\n","\n","# Evaluate the attacker model\n","attacker.eval()\n","all_labels = []\n","all_predicted = []\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for features, labels in new_loader:\n","        features, labels = features.to(device), labels.to(device)\n","        outputs = attacker(features).squeeze()\n","        predicted = (outputs > 0.5).float()\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        all_labels.extend(labels.cpu().numpy())\n","        all_predicted.extend(predicted.cpu().numpy())\n","\n","accuracy = correct / total\n","print(f'Training Accuracy: {accuracy:.4f}')\n","\n","cm = confusion_matrix(all_labels, all_predicted)\n","precision = precision_score(all_labels, all_predicted)\n","recall = recall_score(all_labels, all_predicted)\n","f1 = f1_score(all_labels, all_predicted)\n","\n","print(f'Confusion Matrix:\\n{cm}')\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYQChEAGvnE-","executionInfo":{"status":"ok","timestamp":1719996393097,"user_tz":-210,"elapsed":58774,"user":{"displayName":"Pooria Rad","userId":"18089175725627319477"}},"outputId":"1fe32b09-abef-417b-c49a-93f6048afa5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1u8TtbKu-IYn4BM2fMxlKuSxebGm8t0a8\n","To: /content/list.txt\n","100%|██████████| 231k/231k [00:00<00:00, 39.1MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=13JqLGTHtspZes2xc3JHPgszM2RkvJtsR\n","To: /content/model_state_dict.pth\n","100%|██████████| 1.63M/1.63M [00:00<00:00, 59.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../cifar10/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 48786921.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../cifar10/cifar-10-python.tar.gz to ../cifar10\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.6783\n","Epoch 2, Loss: 0.6702\n","Epoch 3, Loss: 0.6688\n","Epoch 4, Loss: 0.6672\n","Epoch 5, Loss: 0.6667\n","Epoch 6, Loss: 0.6660\n","Epoch 7, Loss: 0.6654\n","Epoch 8, Loss: 0.6648\n","Epoch 9, Loss: 0.6645\n","Epoch 10, Loss: 0.6645\n","Training Accuracy: 0.5917\n","Confusion Matrix:\n","[[ 9361 10639]\n"," [ 5692 14308]]\n","Precision: 0.5735\n","Recall: 0.7154\n","F1 Score: 0.6367\n"]}]},{"cell_type":"code","source":["import gdown\n","from torchvision import models\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torchvision.datasets import CIFAR10\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score ,f1_score\n","from torch.utils.data import Subset, TensorDataset\n","\n","# Download the files from Google Drive\n","gdown.download('https://drive.google.com/uc?id=1u8TtbKu-IYn4BM2fMxlKuSxebGm8t0a8', 'list.txt', quiet=False)\n","gdown.download('https://drive.google.com/uc?id=13JqLGTHtspZes2xc3JHPgszM2RkvJtsR', 'model_state_dict.pth', quiet=False)\n","\n","class CIFAR10Classifier(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10Classifier, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        self.dropout1 = nn.Dropout2d(0.25)\n","        self.dropout2 = nn.Dropout2d(0.5)\n","        self.fc1 = nn.Linear(6272, 64)\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        return x\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Load the pre-trained model\n","model = CIFAR10Classifier()\n","state_dict = torch.load(\"model_state_dict.pth\", map_location=device)\n","new_state_dict = {key.replace('_module.', ''): value for key, value in state_dict.items()}\n","model.load_state_dict(new_state_dict)\n","model.to(device)\n","model.eval()\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","DATA_ROOT = '../cifar10'\n","BATCH_SIZE = 64\n","\n","# Load the indices from list.txt\n","indices_file = 'list.txt'\n","with open(indices_file, 'r') as f:\n","    indices = [int(line.strip()) for line in f]\n","\n","full_train_dataset = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform)\n","test_dataset = CIFAR10(root=DATA_ROOT, train=False, download=True, transform=transform)\n","\n","train_indices_set = set(indices)\n","all_indices_set = set(range(len(full_train_dataset)))\n","other_indices = list(all_indices_set - train_indices_set)\n","\n","train_dataset = Subset(full_train_dataset, indices[:len(indices)//2])\n","other_dataset = Subset(full_train_dataset, other_indices)\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","other_loader = DataLoader(other_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Create labels\n","train_labels = torch.ones(len(train_dataset)).to(device)\n","other_labels = torch.zeros(len(other_dataset)).to(device)\n","test_labels = torch.zeros(len(test_dataset)).to(device)\n","\n","def extract_features(model, dataloader):\n","    model.eval()\n","    features = []\n","    with torch.no_grad():\n","        for data in dataloader:\n","            inputs, _ = data\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            features.append(outputs)\n","    return torch.cat(features).to(device)\n","\n","train_features = extract_features(model, train_loader)\n","other_features = extract_features(model, other_loader)\n","test_features = extract_features(model, test_loader)\n","\n","combined_features = torch.cat((train_features, other_features, test_features))\n","combined_labels = torch.cat((train_labels, other_labels, test_labels))\n","\n","new_dataset = TensorDataset(combined_features, combined_labels)\n","new_loader = DataLoader(new_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Define and train the attacker model\n","class AttackerModel(nn.Module):\n","    def __init__(self):\n","        super(AttackerModel, self).__init__()\n","        self.fc1 = nn.Linear(10, 128)  # Increased hidden layer size\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = torch.sigmoid(self.fc3(x))\n","        return x\n","\n","attacker = AttackerModel().to(device)\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(attacker.parameters(), lr=0.0001)  # Adjusted learning rate\n","\n","EPOCHS = 20  # Increased number of epochs\n","\n","for epoch in range(EPOCHS):\n","    attacker.train()\n","    running_loss = 0.0\n","    for features, labels in new_loader:\n","        features, labels = features.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = attacker(features).squeeze()\n","        loss = criterion(outputs, labels.float())\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(new_loader):.4f}')\n","\n","# Evaluate the attacker model\n","attacker.eval()\n","all_labels = []\n","all_predicted = []\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for features, labels in new_loader:\n","        features, labels = features.to(device), labels.to(device)\n","        outputs = attacker(features).squeeze()\n","        predicted = (outputs > 0.5).float()\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        all_labels.extend(labels.cpu().numpy())\n","        all_predicted.extend(predicted.cpu().numpy())\n","\n","accuracy = correct / total\n","print(f'Training Accuracy: {accuracy:.4f}')\n","\n","cm = confusion_matrix(all_labels, all_predicted)\n","precision = precision_score(all_labels, all_predicted)\n","recall = recall_score(all_labels, all_predicted)\n","f1 = f1_score(all_labels, all_predicted)\n","\n","print(f'Confusion Matrix:\\n{cm}')\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNT2DD775Phv","executionInfo":{"status":"ok","timestamp":1719996648297,"user_tz":-210,"elapsed":42162,"user":{"displayName":"Pooria Rad","userId":"18089175725627319477"}},"outputId":"bcb7148e-80df-4452-cec7-000c17c2cd6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1u8TtbKu-IYn4BM2fMxlKuSxebGm8t0a8\n","To: /content/list.txt\n","100%|██████████| 231k/231k [00:00<00:00, 59.5MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=13JqLGTHtspZes2xc3JHPgszM2RkvJtsR\n","To: /content/model_state_dict.pth\n","100%|██████████| 1.63M/1.63M [00:00<00:00, 74.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.6820\n","Epoch 2, Loss: 0.6738\n","Epoch 3, Loss: 0.6704\n","Epoch 4, Loss: 0.6687\n","Epoch 5, Loss: 0.6677\n","Epoch 6, Loss: 0.6667\n","Epoch 7, Loss: 0.6659\n","Epoch 8, Loss: 0.6653\n","Epoch 9, Loss: 0.6646\n","Epoch 10, Loss: 0.6643\n","Epoch 11, Loss: 0.6639\n","Epoch 12, Loss: 0.6636\n","Epoch 13, Loss: 0.6629\n","Epoch 14, Loss: 0.6627\n","Epoch 15, Loss: 0.6624\n","Epoch 16, Loss: 0.6620\n","Epoch 17, Loss: 0.6616\n","Epoch 18, Loss: 0.6616\n","Epoch 19, Loss: 0.6613\n","Epoch 20, Loss: 0.6611\n","Training Accuracy: 0.5955\n","Confusion Matrix:\n","[[10701  9299]\n"," [ 6883 13117]]\n","Precision: 0.5852\n","Recall: 0.6559\n","F1 Score: 0.6185\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"EBXZ2nBNyWBr"},"execution_count":null,"outputs":[]}]}